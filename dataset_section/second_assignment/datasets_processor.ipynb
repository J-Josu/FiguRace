{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"><img src=\"https://media.giphy.com/media/YjPhjzR0z8qpqtPFyx/giphy.gif\" style = \"height:38px\"/> Procesamiento de los Datasets con Pandas <img src=\"https://media.giphy.com/media/A8ZKGHwM5lWpSqd8rX/giphy.gif\" style = \"height:38px\"/></h1 >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tarjetas de FiguRace se generan a partir de un conjunto de datos que deberán ser preparados previamente. Como parte del proyecto se deberá desarrollar un cuaderno de Jupyter Notebook que extraiga los datos necesarios para el juego de alguno de los datasets provistos y muestre en forma detallada el proceso realizado con los mismos . En el Anexo II se detallan los datasets que deberán utilizar para la aplicación y las modificaciones necesarias para luego guardarlo en un nuevo archivo en formato CSV. El juego deberá cargar esos archivos CSV para funcionar\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /> Spotify 2010 - 2019 Top 100 <img  src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /></h5> </td> <td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /> FIFA-21 Complete <img  src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /></h5> </td><td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /> Lagos Argentina - Hoja 1 <img  src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /></h5> </td>\n",
    "\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma: <br>\n",
    "\n",
    "- Poner en `title case` los géneros musicales excepto las siglas EDM, DFW, UK, R&B y LGBTQ+ que deben ir en mayúsculas. Por ejemplo `dfw rap` debe ser transformado a `DFW Rap`.<br>\n",
    "\n",
    "- Considerar también la excepción `k-pop` que debe ser transformada a `K-Pop`.<br>\n",
    "\n",
    "- Se utilizarán como datos de las tarjetas `Top Genre`, `Year Released`, `BPM`, `Top Year` y `Artist Type`. Como dato a adivinar se utilizará `Artist`. Descartar el resto de las columnas.<br>\n",
    "\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Top Genre`, `Artist Type`, `Year Released`, `Top Year`, `BPM` y `Artist`<br>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Reemplazar `Potential` por la siguiente escala conceptual:<br>\n",
    "  - Regular: Menos de 60<br>\n",
    "  - Bueno: Entre 60 y 79 (inclusive)<br>\n",
    "  - Muy bueno: Entre 80 y 89 (inclusive)<br>\n",
    "  - Sobresaliente: Desde 90 en adelante.<br>\n",
    "- Reemplazar el valor de `Position` por las posiciones en español. Por ejemplo `LB|CB` debe ser reemplazado por `Defensor izquierdo|Defensor central`<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Age`, `Nationality`, `Position`, `Team` y `Potential`. Como dato a adivinar se utilizará `Name`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Team`, `Nationality`, `Position`, `Age`, `Potential` y `Name`.<br>\n",
    " \n",
    "</td>\n",
    " <td>\n",
    " \n",
    "\n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Transformar las coordenadas en la columna `Coordenadas` a grados decimales.<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas`. Como dato a adivinar se utilizará `Nombre`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas` y `Nombre`.<br>\n",
    " \n",
    "</td>\n",
    "</tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importamos las librerias \n",
    "- `POTENTIAL_TABLE_FIFA` es un diccionario en el que almacenamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "POTENTIAL_TABLE_FIFA = {\n",
    "    90: 'Sobresaliente',\n",
    "    80: 'Muy bueno',\n",
    "    60: 'Bueno',\n",
    "    -1: 'Regular'\n",
    "}\n",
    "\n",
    "POSITION_TABLE_FIFA = {\n",
    "    'ST': 'Delantero',\n",
    "    'CM': 'Volante',\n",
    "    'CDM': 'Medio centro defensivo',\n",
    "    'LB': 'Lateral izquierdo',\n",
    "    'GK': 'Portero',\n",
    "    'LM': 'Volante izquierdo',\n",
    "    'RM': 'Volante derecho',\n",
    "    'CAM': 'Volante ofensivo',\n",
    "    'LW': 'Extremo izquierdo',\n",
    "    'LWB': 'Lateral izquierdo ofensivo',\n",
    "    'CB': 'Defensor central',\n",
    "    'RB': 'Lateral derecho',\n",
    "    'RW': 'Extremo derecho',\n",
    "    'RWB': 'Lateral ofensivo derecho',\n",
    "    'CF': 'Media punta'\n",
    "}\n",
    "\n",
    "UPPER_GENDERS_SPOTIFY = [\"EDM\", \"DFW\", \"UK\", \"R&B\", \"LGBTQ+\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_replace(potential:str):\n",
    "    compare_potential = int(potential)\n",
    "    for potential_player in POTENTIAL_TABLE_FIFA:\n",
    "        if compare_potential >= potential_player:\n",
    "            potential = POTENTIAL_TABLE_FIFA[potential_player]\n",
    "            break\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_replace(position:str):\n",
    "    positions = position.split('|')\n",
    "    position = '|'.join([POSITION_TABLE_FIFA[acronym] for acronym in positions])\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_words(sentence:str):\n",
    "    \"\"\"Procesa una frase dependiendo de la consigna\"\"\"\n",
    "    genders = sentence.split()\n",
    "    for index,gender in enumerate(genders):\n",
    "        genders[index] = ( gender.upper() if gender.upper() in UPPER_GENDERS_SPOTIFY else gender.title())\n",
    "    sentence = \" \".join(genders)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebase_coord(coord: str, n_decimals: int = 5) -> str:\n",
    "    sign = -1 if 'S' in coord or 'O' in coord else 1\n",
    "    degree, coord = coord[:-2].split('°')\n",
    "    min, sec = coord.split('\\'')\n",
    "    dd = sign * (int(degree) + int(min)/60 + int(sec)/3600)\n",
    "    return str(round(dd, n_decimals)) + '°'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coords(coords:str) -> str:\n",
    "    latitude, longitude = coords.split()\n",
    "    coords = rebase_coord(latitude) + ' ' + rebase_coord(longitude)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATASETS = {                  \n",
    "    'FIFA-21_Complete.csv':{\n",
    "        'order': [\"team\", \"nationality\", \"position\", \"age\", \"potential\" ,\"name\"],\n",
    "        'translation': ['Equipo', 'Nacionalidad', 'Posición', 'Edad', 'Potencial', 'Nombre'],\n",
    "        'functions': {\n",
    "            \"potential\": potential_replace,\n",
    "            \"position\": position_replace\n",
    "            } ,\n",
    "        'name':\"fifa.csv\"     \n",
    "    },\n",
    "    'Lagos_Argentina - Hoja_1.csv':{\n",
    "        'order': [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"],\n",
    "        'functions': {\n",
    "            \"Coordenadas\": transform_coords\n",
    "            },  \n",
    "        \"name\":'lakes.csv'  \n",
    "    },\n",
    "    'Spotify_2010-2019_Top_100.csv':{\n",
    "        'order': [\"top genre\", \"artist type\", \"year released\", \"top year\", \"bpm\" ,\"artist\"],\n",
    "        'translation': ['Top genero', 'Tipo artista', 'Año lanzamiento','Mejor año', 'BPM', 'Artista'],\n",
    "        'functions': {\n",
    "            \"top genre\":upper_words\n",
    "            },\n",
    "        'name':'spotify.csv'       \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BASE = os.path.dirname(os.getcwd())\n",
    "PATH_SOURCE = os.path.join(PATH_BASE,\"base_datasets\")\n",
    "PATH_PROSSED = os.path.join(PATH_BASE,\"processed_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_name:str):\n",
    "    if file_name not in DATASETS:\n",
    "        return\n",
    "    file_path = os.path.join(PATH_SOURCE,file_name)\n",
    "    config = DATASETS[file_name]\n",
    "    processed_path = os.path.join(PATH_PROSSED,config['name'])\n",
    "    \n",
    "    with open(file_path, mode = 'r',encoding=\"UTF-8\") as file :\n",
    "        df = pd. read_csv (file, sep = None,engine=\"python\",usecols = (config['order']))\n",
    "        df.dropna(how=\"all\" ,inplace=True)\n",
    "        df = df[config['order']] \n",
    "        for columna,function in config['functions'].items():  \n",
    "            df[columna] = df[columna].apply(function) \n",
    "        if 'translation' in config:\n",
    "            df.rename(\n",
    "                {   \n",
    "                    column_name:translation_name\n",
    "                    for column_name,translation_name in zip(config['order'],config['translation'])\n",
    "                },\n",
    "                inplace=True,\n",
    "                axis= 1\n",
    "            )                  \n",
    "        df.to_csv(processed_path, mode='w',index=False)            \n",
    "    \n",
    "names_files = os.listdir(PATH_SOURCE)\n",
    "for file_name in names_files: \n",
    "    process_dataset(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80756411583af035d9a6199794371ea696bdbbbc86d4f210b34cb3d9a731db47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
