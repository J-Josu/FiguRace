{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<h1 align =\"center\"><img src=\"https://media.giphy.com/media/LMt9638dO8dftAjtco/giphy.gif\" style = \"height:38px\"/> Carga de datos <img src=\"https://media.giphy.com/media/TEdRZnV7l3S067fiGR/giphy.gif\" style = \"height:38px\"/></h1 >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tarjetas de FiguRace se generan a partir de un conjunto de datos que deberán ser preparados previamente. Como parte del proyecto se deberá desarrollar un cuaderno de Jupyter Notebook que extraiga los datos necesarios para el juego de alguno de los datasets provistos y muestre en forma detallada el proceso realizado con los mismos . En el Anexo II se detallan los datasets que deberán utilizar para la aplicación y las modificaciones necesarias para luego guardarlo en un nuevo archivo en formato CSV. El juego deberá cargar esos archivos CSV para funcionar\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /> Spotify 2010 - 2019 Top 100 <img  src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /></h5> </td> <td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /> Lagos Argentina - Hoja 1 <img  src=\"https://media.giphy.com/media/YOk7USZ9k8yF4R0yn3/giphy.gif\" style = \"height:38px\" /></h5> </td><td> <h5 align=\"center\"><img src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /> FIFA-21 Complete <img  src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /></h5> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma: <br>\n",
    "\n",
    "- Poner en `title case` los géneros musicales excepto las siglas EDM, DFW, UK, R&B y LGBTQ+ que deben ir en mayúsculas. Por ejemplo `dfw rap` debe ser transformado a `DFW Rap`.<br>\n",
    "\n",
    "- Considerar también la excepción `k-pop` que debe ser transformada a `K-Pop`.<br>\n",
    "\n",
    "- Se utilizarán como datos de las tarjetas `Top Genre`, `Year Released`, `BPM`, `Top Year` y `Artist Type`. Como dato a adivinar se utilizará `Artist`. Descartar el resto de las columnas.<br>\n",
    "\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Top Genre`, `Artist Type`, `Year Released`, `Top Year`, `BPM` y `Artist`<br>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    " \n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Reemplazar `Potential` por la siguiente escala conceptual:<br>\n",
    "  - Regular: Menos de 60<br>\n",
    "  - Bueno: Entre 60 y 79 (inclusive)<br>\n",
    "  - Muy bueno: Entre 80 y 89 (inclusive)<br>\n",
    "  - Sobresaliente: Desde 90 en adelante.<br>\n",
    "- Reemplazar el valor de `Position` por las posiciones en español. Por ejemplo `LB|CB` debe ser reemplazado por `Defensor izquierdo|Defensor central`<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Age`, `Nationality`, `Position`, `Team` y `Potential`. Como dato a adivinar se utilizará `Name`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Team`, `Nationality`, `Position`, `Age`, `Potential` y `Name`.<br>\n",
    " \n",
    "</td>\n",
    " <td>\n",
    " \n",
    "\n",
    "Deberá adaptar los datos de la siguiente forma:<br>\n",
    "\n",
    "- Transformar las coordenadas en la columna `Coordenadas` a grados decimales.<br>\n",
    "- Se utilizarán como datos de las tarjetas: `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas`. Como dato a adivinar se utilizará `Nombre`. Descartar el resto de las columnas.<br>\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas` y `Nombre`.<br>\n",
    " \n",
    "</td>\n",
    "</tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos las constantes\n",
    "--------------------------\n",
    "\n",
    "- `UPPER_GENDERS` : Contiene la lista de palabras que tenemos que convertir completamente a mayuscula\n",
    "- `ORDEN` : El orden en el que tienen que quedar las columnas\n",
    "- `NAMES_REMOVE` : Las columnas que tengo que dejar en el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fabian\\\\Desktop\\\\PysimpleGuy\\\\grupo27'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constantes y variables globales\n",
    "import os\n",
    "import csv\n",
    "UPPER_GENDERS_SPOTIFY = [\"EDM\", \"DFW\", \"UK\", \"R&B\", \"LGBTQ+\"]\n",
    "ORDEN_SPOTIFY = [\"Top Genre\", \"Artist Type\", \"Year Released\", \"Top Year\", \"BPM\" ,\"Artist\"]\n",
    "ORDEN_LAGOS = [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"]\n",
    "ORDEN_FIFA21 = [\"Team\", \"Nationality\", \"Position\", \"Age\", \"Potential\" ,\"Name\"]\n",
    "ALL_ORDEN_REMOVE = [ORDEN_SPOTIFY,ORDEN_LAGOS,ORDEN_FIFA21]\n",
    "\n",
    "NAMES_REMOVE_SPOTIFY = [\"Top Genre\", \"Year Released\",\"BPM\", \"Top Year\", \"Artist Type\",\"Artist\"]\n",
    "NAMES_REMOVE_LAGOS = [\"Ubicación\", \"Superficie (km²)\", \"Profundidad máxima (m)\", \"Profundidad media (m)\", \"Coordenadas\"]\n",
    "NAMES_REMOVE_FIFA21 = [\"Age\", \"Nationality\", \"Position\", \"Team\" , \"Potential\",\"Name\"]\n",
    "ALL_NAMES_REMOVE = [NAMES_REMOVE_SPOTIFY,NAMES_REMOVE_LAGOS,NAMES_REMOVE_FIFA21]\n",
    "\n",
    "NAMES_DATASETS = [\"Spotify_2010-2019_Top_100.csv\",\"Lagos_Argentina - Hoja_1.csv\",\"FIFA-21_Complete.csv\"]\n",
    "\n",
    "\n",
    "path = os.path.dirname(os.path.realpath(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesando los datos\n",
    "\n",
    "Separamos el encabezado de el resto del archivo ya que mas adelante vamos a utilizarlo/modificarlo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufefftitle',\n",
       " 'artist',\n",
       " 'top genre',\n",
       " 'year released',\n",
       " 'added',\n",
       " 'bpm',\n",
       " 'nrgy',\n",
       " 'dnce',\n",
       " 'dB',\n",
       " 'live',\n",
       " 'val',\n",
       " 'dur',\n",
       " 'acous',\n",
       " 'spch',\n",
       " 'pop',\n",
       " 'top year',\n",
       " 'artist type']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_process(path:str):\n",
    "    \"\"\"Separa los datos_spotify del archivo \n",
    "    \"\"\"\n",
    "    all_header:list[list[str]] = [] #Guardo todos los encabezados\n",
    "    all_datos: list[list[list[str]]]= []\n",
    "    all_path_file:list[str] = []\n",
    "    [all_path_file.append(os.path.join(path,\"grupo27\",\"dataset_section\",\"base_datasets\",NAMES_DATASETS[index])) for index in range(0,len(NAMES_DATASETS))]\n",
    "    for index in range(0,len(all_path_file)):\n",
    "        with open(all_path_file[index],\"r\", encoding=\"utf-8\") as File:  \n",
    "            if not(index == 2):\n",
    "                csv_reader = csv.reader(File, delimiter=',')\n",
    "            else:\n",
    "                csv_reader = csv.reader(File, delimiter=';')\n",
    "            all_header.append(next(csv_reader)) # El encabezado para comparar las columnas borradas\n",
    "            all_datos.append(list(csv_reader))\n",
    "    return all_header,all_datos\n",
    "all_header,all_datos = data_process(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una constante que contiene el orden en el que tenemos que dejar las columnas `ORDEN`.\n",
    "\n",
    "- Pasamos esta lista a minuscula para comparar y la recorremos\n",
    "- Cargamos la lista con los indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 16, 3, 15, 5, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_order(orden_list:list[int],name_remove:list[str],header:list[str]):\n",
    "    # Columnas para invertir datos_spotify\n",
    "    \"\"\"Crea un orden a partir de dos listas.\\n\n",
    "    Ej: hola, chau, bye\\n\n",
    "    [0, 1, 2]\\n\n",
    "    Y queremos que este en este orden\\n\n",
    "    Ej: bye, hola, chau\\n\n",
    "    Genera una lista con:\\n\n",
    "    [2, 0, 1]\n",
    "    \"\"\"\n",
    "    names_compare = list(map(lambda x: x.lower(), name_remove))\n",
    "    header_compare = list(map(lambda x: x.lower(), header))\n",
    "    for name in names_compare:\n",
    "        for pos,dato in enumerate(header_compare):\n",
    "            if (name == dato):\n",
    "                orden_list.append(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de Columnas\n",
    "\n",
    "- Separamos las columnas que queremos mantener de las que vamos a eliminar\n",
    "- Generamos sus respectivas listas, con los indices para reutilizar el codigo en un futuro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], [1, 2, 3, 5, 15, 16])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separate_cols(all_cols_remove:list[list[int]],all_header:list[list[str]]):\n",
    "    \"\"\"Separa las columnas de las que quiero eliminar\n",
    "    \"\"\"\n",
    "    for index,name_remove in enumerate(ALL_NAMES_REMOVE):\n",
    "        cols_remove:list[int] = []\n",
    "        names_compare = (list(map(lambda x: x.lower(), name_remove))) # Creamos una lista para comparar\n",
    "        header = all_header[index]\n",
    "        for column in header:    # Recorro el encabezado actual\n",
    "            if not(column.lower() in names_compare):\n",
    "                index_dato = header.index(column)\n",
    "                cols_remove.append(index_dato)\n",
    "        all_cols_remove.append(cols_remove)\n",
    "all_cols_remove:list[list[int]] = []  # Columnas que voy a eliminar [0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]  \n",
    "separate_cols(all_cols_remove,all_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos Columnas\n",
    "\n",
    "- Recorremos todo el archivo\n",
    "  - Recorremos una fila\n",
    "    - Ordenamos las columnas dependiendo de cual sea su indice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_sorted(row:list[str],orden_list:list[int]): # [0, 1, 2, 3, 4, 5]\n",
    "    \"\"\"Intercambialas posiciones de una lista\n",
    "    \"\"\"\n",
    "    row_copia = row.copy()\n",
    "    for indice,dato in enumerate(orden_list):        # [1, 5, 2, 4, 3, 0]    \n",
    "        row[indice]= row_copia[dato]                       \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mayusculas-Minusculas\n",
    "\n",
    "- Con la frase que tenemos, generamos una lista de palabras para poder trabajar en cada una de ellas por separado\n",
    "- Recorremos la lista\n",
    "  - Si se encuentra en la lista, la convertimos toda a mayuscula\n",
    "  - Sino usamos `title()` para pasar la primera a mayuscula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_words(word:str):\n",
    "    \"\"\"Procesa una frase dependiendo de la consigna\"\"\"\n",
    "    genders = word.split()\n",
    "    for index, gender in enumerate(genders):\n",
    "        if gender.upper() in UPPER_GENDERS_SPOTIFY:\n",
    "            genders[index]= gender.upper()\n",
    "        else:\n",
    "            genders[index]= gender.title()\n",
    "    word = \" \".join(genders)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para eliminar las columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_remove_function(row:list[str],cols_remove:list[int]):\n",
    "    \"\"\"Elimina posiciones de una lista (las posiciones son pasadas por parametro)\"\"\"\n",
    "    for col_index in cols_remove:\n",
    "        del (row[col_index])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist type', 'Year Released', 'top year', 'added', '\\ufefftitle', 'bpm']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,col in enumerate(all_cols_remove):\n",
    "    all_cols_remove[index] = sorted(col, reverse=True) # En reverso para sacar primero las columnas desde el final\n",
    "\n",
    "def first_order(NewFile):\n",
    "    csv_writer = csv.writer(NewFile)\n",
    "    header_orden = all_header[index].copy()\n",
    "    cols_remove_function(header_orden,all_cols_remove[index])\n",
    "    orden_list:list[int] = []  \n",
    "    create_order(orden_list,ALL_ORDEN_REMOVE[index],header_orden)\n",
    "    return csv_writer,orden_list\n",
    "\n",
    "for index,name_dataset in enumerate(NAMES_DATASETS):\n",
    "    path_newfile = os.path.join(path,\"grupo27\", \"dataset_section\", \"processed_datasets\", name_dataset)\n",
    "    with open(path_newfile, \"w\",encoding=\"utf-8\",newline='') as NewFile:\n",
    "        csv_writer,orden_list=first_order(NewFile)\n",
    "        all_datos[index].insert(0,all_header[index]) \n",
    "        print(orden_list)\n",
    "        if (index == 0): # Spoty\n",
    "            for row in all_datos[index]:\n",
    "                row[2] = upper_words(row[2])\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "                csv_writer.writerow(row)\n",
    "        if (index == 1): # Lagos\n",
    "            for row in all_datos[index]:\n",
    "                row[2] = upper_words(row[2])\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "                csv_writer.writerow(row)\n",
    "        if (index == 2): # Fifa\n",
    "            for row in all_datos[index]:\n",
    "                row[2] = upper_words(row[2])\n",
    "                row = cols_remove_function(row,all_cols_remove[index])\n",
    "                row = cols_sorted(row,orden_list)\n",
    "                csv_writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80756411583af035d9a6199794371ea696bdbbbc86d4f210b34cb3d9a731db47"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
