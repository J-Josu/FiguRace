{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<h1 ><img src=\"https://media.giphy.com/media/LMt9638dO8dftAjtco/giphy.gif\" style = \"height:38px\"/> Carga de datos <img src=\"https://media.giphy.com/media/TEdRZnV7l3S067fiGR/giphy.gif\" style = \"height:38px\"/></h1 >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tarjetas de FiguRace se generan a partir de un conjunto de datos que deberán ser preparados previamente. Como parte del proyecto se deberá desarrollar un cuaderno de Jupyter Notebook que extraiga los datos necesarios para el juego de alguno de los datasets provistos y muestre en forma detallada el proceso realizado con los mismos . En el Anexo II se detallan los datasets que deberán utilizar para la aplicación y las modificaciones necesarias para luego guardarlo en un nuevo archivo en formato CSV. El juego deberá cargar esos archivos CSV para funcionar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"><img src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /> Spotify 2010 - 2019 Top 100 <img  src=\"https://media.giphy.com/media/F3IsWfsR1JMyNmL44Z/giphy.gif\" style = \"height:38px\" /></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberá adaptar los datos de la siguiente forma:\n",
    "\n",
    "- Poner en `title case` los géneros musicales excepto las siglas EDM, DFW, UK, R&B y LGBTQ+ que deben ir en mayúsculas. Por ejemplo `dfw rap` debe ser transformado a `DFW Rap`.\n",
    "- Considerar también la excepción `k-pop` que debe ser transformada a `K-Pop`.\n",
    "- Se utilizarán como datos de las tarjetas `Top Genre`, `Year Released`, `BPM`, `Top Year` y `Artist Type`. Como dato a adivinar se utilizará `Artist`. Descartar el resto de las columnas.\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Top Genre`, `Artist Type`, `Year Released`, `Top Year`, `BPM` y `Artist`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos las constantes\n",
    "--------------------------\n",
    "\n",
    "- `UPPER_GENDERS` : Contiene la lista de palabras que tenemos que convertir completamente a mayuscula\n",
    "- `ORDEN` : El orden en el que tienen que quedar las columnas\n",
    "- `NAMES_REMOVE` : Las columnas que tengo que dejar en el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fabian\\\\Desktop\\\\PysimpleGuy\\\\grupo27'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constantes y variables globales\n",
    "import os\n",
    "import csv\n",
    "UPPER_GENDERS = [\"EDM\", \"DFW\", \"UK\", \"R&B\", \"LGBTQ+\"]\n",
    "ORDEN = [\"Top Genre\", \"Artist Type\", \"Year Released\", \"Top Year\", \"BPM\" ,\"Artist\"]\n",
    "NAMES_REMOVE = [\"Artist\", \"Top Genre\", \"Year Released\",\"BPM\", \"Top Year\", \"Artist Type\"]\n",
    "path = os.path.dirname(os.path.realpath(\".\"))\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesando los datos\n",
    "\n",
    "Separamos el encabezado de el resto del archivo ya que mas adelante vamos a utilizarlo/modificarlo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufefftitle',\n",
       " 'artist',\n",
       " 'top genre',\n",
       " 'year released',\n",
       " 'added',\n",
       " 'bpm',\n",
       " 'nrgy',\n",
       " 'dnce',\n",
       " 'dB',\n",
       " 'live',\n",
       " 'val',\n",
       " 'dur',\n",
       " 'acous',\n",
       " 'spch',\n",
       " 'pop',\n",
       " 'top year',\n",
       " 'artist type']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_process(path:str):\n",
    "    header:list[str] = []\n",
    "    datos:list[list[str]] = []\n",
    "    path_file = os.path.join(path,\"dataset_section\", \"base_datasets\", 'Spotify_2010-2019_Top_100.csv')\n",
    "    with open(path_file,\"r\", encoding=\"utf-8\") as File:  \n",
    "        csv_reader = csv.reader(File, delimiter=',')\n",
    "        header = next(csv_reader) # El encabezado para comparar las columnas borradas\n",
    "        datos = list(csv_reader)\n",
    "    return header,datos\n",
    "\n",
    "header,datos = data_process(path)\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos una constante que contiene el orden en el que tenemos que dejar las columnas `ORDEN`.\n",
    "\n",
    "- Pasamos esta lista a minuscula para comparar y la recorremos\n",
    "- Cargamos la lista con los indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 16, 3, 15, 5, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_order(orden_list:list[int]):\n",
    "    # Columnas para invertir datos\n",
    "    \"\"\"Agregamos a una lista, los indices manteniendo un orden.\n",
    "    \"\"\"\n",
    "    names_compare = list(map(lambda x: x.lower(), ORDEN))\n",
    "    for name in names_compare:\n",
    "        for pos,dato2 in enumerate(header):\n",
    "            if (name == dato2):\n",
    "                orden_list.append(pos)\n",
    "\n",
    "orden_list:list[int] = []  \n",
    "create_order(orden_list)\n",
    "orden_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de Columnas\n",
    "\n",
    "- Separamos las columnas que queremos mantener de las que vamos a eliminar\n",
    "- Generamos sus respectivas listas, con los indices para reutilizar el codigo en un futuro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], [1, 2, 3, 5, 15, 16])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separate_cols(cols_remove:list[int],cols_saves:list[int]):\n",
    "    names_compare = list(map(lambda x: x.lower(), NAMES_REMOVE)) # Creamos una lista para comparar\n",
    "    for column in header:\n",
    "        if not(column.lower() in names_compare): \n",
    "            index_dato = header.index(column)\n",
    "            cols_remove.append(index_dato)\n",
    "        else:                                 # Para ordenar los datos entre listas\n",
    "            index_dato2 = header.index(column)\n",
    "            cols_saves.append(index_dato2)\n",
    "\n",
    "\n",
    "cols_remove:list[int] = []  # Columnas que voy a eliminar [0, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14] \n",
    "cols_saves:list[int] = []   # Columnas que voy a guardar  [1, 2, 3, 5, 15, 16] \n",
    "separate_cols(cols_remove,cols_saves)\n",
    "cols_remove,cols_saves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenamos Columnas\n",
    "\n",
    "- Recorremos todo el archivo\n",
    "  - Recorremos una fila\n",
    "    - Ordenamos las columnas dependiendo de cual sea su indice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_sorted(datos:list[list[str]],orden_list:list[int]):\n",
    "    for row in datos:\n",
    "        # Recorro la lista de columnas que tengo que intercambiar \n",
    "        # Despues intercambio los datos entre columnas\n",
    "        for col_index in cols_saves:                        # [1, 2, 3, 5, 15, 16]\n",
    "            for indice,dato in enumerate(orden_list):     \n",
    "                if (col_index == dato):                     # [2, 16, 3, 15, 5, 1]\n",
    "                    aux = row[dato]\n",
    "                    row[dato]= row[indice]                  # En lugar de col_index,es la posicion de la tabla\n",
    "                    row[indice] = aux\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mayusculas-Minusculas\n",
    "\n",
    "- Con la frase que tenemos, generamos una lista de palabras para poder trabajar en cada una de ellas por separado\n",
    "- Recorremos la lista\n",
    "  - Si se encuentra en la lista, la convertimos toda a mayuscula\n",
    "  - Sino usamos `title()` para pasar la primera a mayuscula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_words(word:str):\n",
    "    genders = word.split()\n",
    "    for index, gender in enumerate(genders):\n",
    "        if gender.upper() in UPPER_GENDERS:\n",
    "            genders[index]= gender.upper()\n",
    "        else:\n",
    "            genders[index]= gender.title()\n",
    "    word = \" \".join(genders)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para eliminar las columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_remove_function(row:list[str],cols_remove:list[int]):\n",
    "    # Elimino las columnas innecesarias\n",
    "    for col_index in cols_remove:\n",
    "        del (row[col_index])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist type', 'Year Released', 'top year', 'added', '\\ufefftitle', 'bpm']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_remove = sorted(cols_remove, reverse=True) # En reverso para sacar primero las columnas desde el final\n",
    "path_newfile = os.path.join(path, \"dataset_section\", \"processed_datasets\", 'Spotify.processed.csv')\n",
    "\n",
    "with open(path_newfile, \"w\",encoding=\"utf-8\",newline='') as NewFile:\n",
    "    csv_writer = csv.writer(NewFile)\n",
    "    datos.insert(0,header)             # Vuelvo a insertar el encabezado para eliminar las columnas\n",
    "    datos = cols_sorted(datos,orden_list)\n",
    "    for row in datos:\n",
    "        row[2] = upper_words(row[2])\n",
    "        row = cols_remove_function(row,cols_remove)\n",
    "        csv_writer.writerow(row)\n",
    "header     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"><img src=\"https://media.giphy.com/media/QWrCFpI965negKDo0n/giphy.gif\" style = \"height:38px\" /> Lagos Argentina - Hoja 1 <img  src=\"https://media.giphy.com/media/QWrCFpI965negKDo0n/giphy.gif\" style = \"height:38px\" /></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberá adaptar los datos de la siguiente forma:\n",
    "\n",
    "- Transformar las coordenadas en la columna `Coordenadas` a grados decimales.\n",
    "- Se utilizarán como datos de las tarjetas: `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas`. Como dato a adivinar se utilizará `Nombre`. Descartar el resto de las columnas.\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Ubicación`, `Superficie (km²)`, `Profundidad máxima (m)`, `Profundidad media (m)`, `Coordenadas` y `Nombre`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"><img src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /> FIFA-21 Complete <img  src=\"https://media.giphy.com/media/W55QKlBohHZS9RGOWJ/giphy.gif\" style = \"height:38px\" /></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberá adaptar los datos de la siguiente forma:\n",
    "\n",
    "- Reemplazar `Potential` por la siguiente escala conceptual:\n",
    "  - Regular: Menos de 60\n",
    "  - Bueno: Entre 60 y 79 (inclusive)\n",
    "  - Muy bueno: Entre 80 y 89 (inclusive)\n",
    "  - Sobresaliente: Desde 90 en adelante.\n",
    "- Reemplazar el valor de `Position` por las posiciones en español. Por ejemplo `LB|CB` debe ser reemplazado por `Defensor izquierdo|Defensor central`\n",
    "- Se utilizarán como datos de las tarjetas: `Age`, `Nationality`, `Position`, `Team` y `Potential`. Como dato a adivinar se utilizará `Name`. Descartar el resto de las columnas.\n",
    "- El archivo resultante deberá tener las siguientes columnas (en este orden específico): `Team`, `Nationality`, `Position`, `Age`, `Potential` y `Name`.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80756411583af035d9a6199794371ea696bdbbbc86d4f210b34cb3d9a731db47"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
